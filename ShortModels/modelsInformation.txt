A
Our baseline 1D-CNN model that we have created after weeks of experimentation.
We further compare this model with variations shown below, though these do not surpass this model.

model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

B
This model uses MaxPooling rather than AveragePooling, MaxPooling attempts to extract the most important
or 'sharpest' feature. This performed slightly worse than AveragePooling which takes a smoother extraction.

model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(2000, 279)))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

C
This model uses a sigmoid function in its intermediate Dense layer. The intention is to add more capacity for
adding negative weight to certain features, though this performed worse than relu which seeks to focus on 
positive weightings.

model = Sequential()
model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='sigmoid'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

D
This model uses a smaller number of filters, 32 versus 64, the intention is to reduce overfitting, though accuracy
did not improve suggesting 64 filters is appropriate.

model = Sequential()
model.add(Conv1D(filters=32, kernel_size=10, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

E
This model extends upon model D and adds a smaller kernel size, again attempting to reduce any overfitting though 
this did not improve performance.

model = Sequential()
model.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

F
This model extends upon model D and adds a higher kernel size, attempting to increasing fitting
though this did not improve performance.

model = Sequential()
model.add(Conv1D(filters=32, kernel_size=15, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

G
This model reduces kernel size to try and reduce any overfitting.

model = Sequential()
model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

H
This model increases kernel size to try and increase fitting.

model = Sequential()
model.add(Conv1D(filters=64, kernel_size=15, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")

I
This model increases the pooling size of the AveragePooling layer, hoping to create a more generalized
feature map.

model = Sequential()
model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(2000, 279)))
model.add(AveragePooling1D(pool_size=4))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(8, activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer="adam")